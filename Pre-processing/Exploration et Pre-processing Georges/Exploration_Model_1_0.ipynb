{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJxX19_T29Lh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import joblib\n",
        "import utils # contient toutes les fonctions crees pour le projet..\n",
        "\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "awxDKgBT3U3z"
      },
      "source": [
        "### Importation des donnees\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K75IyuXy3jYe"
      },
      "outputs": [],
      "source": [
        "# ROOT = \"/content/drive/Shareddrives/Canvas ECo energy/Eco Energy Energy Live Capstone/datasets/\" # chemin sur colab\n",
        "ROOT = \"C:/Users/georg/OneDrive/Documents/GitHub/CapstoneProjectEnergy/Dataset/\" # chemin en local\n",
        "\n",
        "\n",
        "dred = \"DRED.csv\"\n",
        "qud = \"QUD.csv\"\n",
        "sim = \"SimDataset.csv\"\n",
        "\n",
        "\n",
        "rw_dred = pd.read_csv(ROOT+dred, names= [\"occupancy\", \"P\", \"Pn\", \"P+t1\", \"P-t1\",\"class_state\"], header=None)\n",
        "rw_qud = pd.read_csv(ROOT+qud, names= [\"occupancy\", \"P\", \"Pn\", \"P+t1\", \"P-t1\",\"class_state\"], header=None)\n",
        "rw_sim = pd.read_csv(ROOT+sim, names= ['Occupancy' , 'Appliance_ID' , 'Sin(time)' , 'Cos(time)' , 'Sin(day)' , 'Cos(day)' , 'Power_consumption_P(t)' , 'Normalized-power-consumption ' , 'P(t)-P(t+1)' , 'P(t)-P(t-1)' , 'Micro-moment_class'], header=None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YJ697uxRZWpD",
        "outputId": "cf54c6ca-6549-452b-e52c-a0f0f59d5254"
      },
      "outputs": [],
      "source": [
        "rw_dred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aqFCTs47ZaBI",
        "outputId": "1b7a9cc3-31af-4567-afd9-af1e5fed2ab7"
      },
      "outputs": [],
      "source": [
        "rw_qud.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cf57NzQxOvj"
      },
      "source": [
        "### Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vemcdj0ggao"
      },
      "outputs": [],
      "source": [
        "# !pip install xgboost"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pHIgEIuQGazw"
      },
      "source": [
        "#### Normalisation avec le coefficient de variance pour le ML"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SIjZ3zw54f8B"
      },
      "source": [
        "Qud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Elyy0n6H3nsx",
        "outputId": "48662c42-0770-4e7c-f9c6-d02767249b2b"
      },
      "outputs": [],
      "source": [
        "rw_qud.shape , rw_qud.shape[0]-3\n",
        "input_qud, output_qud = utils.slide_window(dataset=rw_qud ,window_size=3)\n",
        "input_qud = input_qud.squeeze()\n",
        "\n",
        "new_qud_dataset = np.concatenate((input_qud, np.expand_dims(output_qud, axis=-1)) , axis = 1)\n",
        "\n",
        "df_qud = pd.DataFrame(new_qud_dataset, columns = ['oc1','oc2','oc3','p1','p2','p3','pt01','pt02','pt03' ,'pt11','pt22','pt33' ,'cl1','cl2','cl3', 'out' ] )\n",
        "\n",
        "## normalisons avec le coefficient de variance\n",
        "\n",
        "df_qud['mean'] = (df_qud['p1'] + df_qud['p2'] + df_qud['p3'] ) / 3 # moyenne des valeurs power pour une window\n",
        "df_qud['std_window'] = df_qud[['p2' , 'p2' , 'p3']].std(axis=1) # std de P1, P2, P3\n",
        "df_qud['norm_window'] = ( df_qud['std_window']/df_qud['mean'] ) * ((df_qud[['p1' , 'p2' , 'p3']].max(axis=1) - df_qud[['p1' , 'p2' , 'p3']].min(axis=1)) /1000) # normalization de P1, P2, P3 \n",
        "\n",
        "## visualisation\n",
        "\n",
        "debut = 0\n",
        "fin   = -1\n",
        "\n",
        "plt.plot(df_qud['p2'][debut:fin])\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel(\"Power normalisee\")\n",
        "plt.title(\"Power dans chaque fenetre\" , {'fontsize': 9}  )\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "plt.plot(df_qud['norm_window'][debut:fin])\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel(\"Power normalisee\")\n",
        "plt.title(\"Power normalisee (w) dans chaque fenetre\" , {'fontsize': 9}  )\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "\n",
        "df_qud.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "0xYJM5Bn9K0p",
        "outputId": "30ffbfd0-9511-454d-d3f4-65903c651ed4"
      },
      "outputs": [],
      "source": [
        "# quelques statistiques\n",
        "\n",
        "df_qud.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o-JzFgPI9S_B",
        "outputId": "e79fdba8-9e80-4241-cc08-220d25e2192f"
      },
      "outputs": [],
      "source": [
        "qud_corr = df_qud.corr()\n",
        "sns.heatmap(qud_corr)\n",
        "qud_corr"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hzbj-kEY8xp3"
      },
      "source": [
        "Dred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "flLv1_pu8zps",
        "outputId": "38224758-99e1-4fbb-ea25-3c35b3fa90aa"
      },
      "outputs": [],
      "source": [
        "rw_dred.shape , rw_dred.shape[0]-3\n",
        "input_dred, output_dred = utils.slide_window(dataset=rw_dred ,window_size=3)\n",
        "input_dred = input_dred.squeeze()\n",
        "\n",
        "new_dred_dataset = np.concatenate((input_dred, np.expand_dims(output_dred, axis=-1)) , axis = 1)\n",
        "\n",
        "df_dred = pd.DataFrame(new_dred_dataset, columns = ['oc1','oc2','oc3','p1','p2','p3','pt01','pt02','pt03' ,'pt11','pt22','pt33' ,'cl1','cl2','cl3', 'out' ] )\n",
        "\n",
        "## normalisaons avec le coefficient de variance\n",
        "\n",
        "df_dred['mean'] = (df_dred['p1'] + df_dred['p2'] + df_dred['p3'] ) / 3 # moyenne des valeurs power pour une window\n",
        "df_dred['std_window'] = df_dred[['p2' , 'p2' , 'p3']].std(axis=1) # std de P1, P2, P3\n",
        "df_dred['norm_window'] = ( df_dred['std_window']/df_dred['mean'] ) * ((df_dred[['p1' , 'p2' , 'p3']].max(axis=1) - df_dred[['p1' , 'p2' , 'p3']].min(axis=1)) /1000) # normalization de P1, P2, P3 \n",
        "\n",
        "## visualisation\n",
        "\n",
        "debut = 0\n",
        "fin   = -1\n",
        "\n",
        "plt.plot(df_dred['p2'][debut:fin])\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel(\"Power normalisee\")\n",
        "plt.title(\"Power dans chaque fenetre\" , {'fontsize': 9}  )\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "plt.plot(df_dred['norm_window'][debut:fin])\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel(\"Power normalisee\")\n",
        "plt.title(\"Power normalisee (w) dans chaque fenetre\" , {'fontsize': 9}  )\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "\n",
        "df_dred.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "i1wU1RR6_coK",
        "outputId": "1dcc05f0-7430-4efc-d6e0-a34e0ae701dd"
      },
      "outputs": [],
      "source": [
        "# quelques statistiques\n",
        "\n",
        "df_dred.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "lA-xFa-v_coL",
        "outputId": "2a33db8b-7825-4929-d0a3-12f0ac06cb2c"
      },
      "outputs": [],
      "source": [
        "dred_corr = df_dred.corr()\n",
        "sns.heatmap(dred_corr)\n",
        "df_dred"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LpGVJT8o167_"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYaZcv-m1933"
      },
      "outputs": [],
      "source": [
        "# Separation en train et test\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# dred\n",
        "dred_feature = df_dred.iloc[ : , 1:-3 ].drop( 'out' , axis = 1 )\n",
        "dred_target  = df_dred.iloc[ : , 1:-3 ].out\n",
        "\n",
        "dred_features_train = dred_feature.iloc[ : int(dred_feature.shape[0]*0.8 ) , : ]\n",
        "dred_features_test  = dred_feature.iloc[ int(dred_feature.shape[0]*0.8 ) : , : ]  \n",
        "\n",
        "dred_target_train = dred_target.iloc[ : int(dred_feature.shape[0]*0.8 ) ]\n",
        "dred_target_test  = dred_target.iloc[ int(dred_feature.shape[0]*0.8 ) : ]  \n",
        "\n",
        "# dred_features_train = scaler.fit_transform(dred_features_train)\n",
        "# dred_features_test  = scaler.fit_transform(dred_features_test) \n",
        "\n",
        "\n",
        "# qud\n",
        "qud_feature = df_qud.iloc[ : , 1:-3 ].drop( 'out' , axis = 1 )\n",
        "qud_target  = df_qud.iloc[ : , 1:-3 ].out\n",
        "\n",
        "qud_features_train = qud_feature.iloc[ : int(qud_feature.shape[0]*0.8 ) , : ]\n",
        "qud_features_test  = qud_feature.iloc[ int(qud_feature.shape[0]*0.8 ) : , : ]  \n",
        "\n",
        "qud_target_train = qud_target.iloc[ : int(qud_feature.shape[0]*0.8 ) ]\n",
        "qud_target_test  = qud_target.iloc[ int(qud_feature.shape[0]*0.8 ) : ]  \n",
        "\n",
        "# qud_features_train = scaler.fit_transform(qud_features_train)\n",
        "# qud_features_test  = scaler.fit_transform(qud_features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIkIJkGr17tZ",
        "outputId": "31e43815-dc5f-4395-f6fe-f725f9fe5ce8"
      },
      "outputs": [],
      "source": [
        "# qud\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "\n",
        "xgb.fit(qud_features_train, qud_target_train)\n",
        "yhat = xgb.predict(qud_features_test)\n",
        "\n",
        "print(f\"Les scores de chaque classe: \\n{f1_score(qud_target_test, yhat, average = None)}\")\n",
        "\n",
        "print()\n",
        "macro = f1_score(qud_target_test, yhat, average = \"macro\")\n",
        "print(f\"Les scores de ENSEMBLE classe: \\n{macro}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NihUJ8_P2aQL",
        "outputId": "b5b6b4c6-e70e-4584-bdce-b11462c58491"
      },
      "outputs": [],
      "source": [
        "# dred\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "\n",
        "xgb.fit(dred_features_train, dred_target_train)\n",
        "yhat = xgb.predict(dred_features_test)\n",
        "\n",
        "\n",
        "print(f\"Les scores de chaque classe: \\n{f1_score(dred_target_test, yhat, average = None)}\")\n",
        "\n",
        "print()\n",
        "macro = f1_score(dred_target_test, yhat, average = \"macro\")\n",
        "print(f\"Les scores de ENSEMBLE classe: \\n{macro}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V6ti1nUlGiC3"
      },
      "source": [
        "### Normalisation avec le stateful pour le ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5fU9ULGGpSo",
        "outputId": "5421a9ec-a55c-4b5e-e798-85629e30adac"
      },
      "outputs": [],
      "source": [
        "# drop de la colonne de la \"power normalized\"\n",
        "\n",
        "dred_dropped = rw_dred.drop('Pn', axis=1)\n",
        "qud_dropped  = rw_qud.drop('Pn', axis=1)\n",
        "\n",
        "print(dred_dropped.head())\n",
        "print()\n",
        "print(qud_dropped.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYujhpOyameB",
        "outputId": "568e81de-c0c9-4149-ca9c-bd4796874ef7"
      },
      "outputs": [],
      "source": [
        "processor = utils.DataProcessing(qud_dropped)\n",
        "X_qud , y_qud = processor.processing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_ruE0kh0UHF",
        "outputId": "fbec07ac-892f-440a-a0b3-768a0e4016c9"
      },
      "outputs": [],
      "source": [
        "processor = utils.DataProcessing(dred_dropped)\n",
        "X_dred , y_dred = processor.processing()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r-hFogxXpuHt"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyOfrK2Gju7r",
        "outputId": "187514c5-1f91-4c0a-f26a-d0889a92c2c8"
      },
      "outputs": [],
      "source": [
        "# qud\n",
        "\n",
        "qud_features_train_sf = X_qud[ : int(X_qud.shape[0]*0.8 ) , : ]\n",
        "qud_features_test_sf  = X_qud[ int(X_qud.shape[0]*0.8 ) : , : ]  \n",
        "\n",
        "qud_target_train_sf = y_qud[ : int(y_qud.shape[0]*0.8 ) ]\n",
        "qud_target_test_sf  = y_qud[ int(y_qud.shape[0]*0.8 ) : ]  \n",
        "\n",
        "# print(qud_features_train_sf)\n",
        "# print()\n",
        "# print(qud_target_train_sf)\n",
        "\n",
        "\n",
        "xgb_sf = XGBClassifier()\n",
        "\n",
        "\n",
        "xgb.fit(qud_features_train_sf, qud_target_train_sf)\n",
        "yhat = xgb.predict(qud_features_test_sf)\n",
        "\n",
        "\n",
        "print(f\"Les scores de chaque classe: \\n{f1_score(qud_target_test_sf, yhat, average = None)}\")\n",
        "\n",
        "print()\n",
        "macro = f1_score(qud_target_test, yhat, average = \"macro\")\n",
        "print(f\"Les scores de ENSEMBLE classe: \\n{macro}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsBpF2JfibVU",
        "outputId": "7f22310c-4eb8-4349-b517-d8dbe5b932bd"
      },
      "outputs": [],
      "source": [
        "# dred\n",
        " \n",
        "dred_features_train_sf = X_dred[ : int(X_dred.shape[0]*0.8 ) , : ]\n",
        "dred_features_test_sf  = X_dred[ int(X_dred.shape[0]*0.8 ) : , : ]  \n",
        "\n",
        "dred_target_train_sf = y_dred[ : int(y_dred.shape[0]*0.8 ) ]\n",
        "dred_target_test_sf  = y_dred[ int(y_dred.shape[0]*0.8 ) : ]  \n",
        "\n",
        "# print(dred_features_test_sf.shape)\n",
        "# print()\n",
        "# print(dred_target_test_sf.shape)\n",
        "\n",
        "\n",
        "\n",
        "xgb_sf = XGBClassifier()\n",
        "\n",
        "\n",
        "xgb.fit(dred_features_train_sf, dred_target_train_sf)\n",
        "yhat = xgb.predict(dred_features_test_sf)\n",
        "\n",
        "\n",
        "print(f\"Les scores de chaque classe: \\n{f1_score(dred_target_test_sf, yhat, average = None)}\")\n",
        "\n",
        "print()\n",
        "# print(dred_target_test.shape)\n",
        "# print(yhat.shape)\n",
        "macro = f1_score(dred_target_test_sf, yhat, average = \"macro\")\n",
        "print(f\"Les scores de ENSEMBLE classe: \\n{macro}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YI5EvZa4Iv5q"
      },
      "source": [
        "Sauvegarde du meilleur model en ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMJrgbEIIw_8"
      },
      "outputs": [],
      "source": [
        "# avec pickle\n",
        "\n",
        "filename = '/Models/best2_model.sav'\n",
        "pickle.dump(xgb, open(filename, 'wb'))\n",
        "\n",
        "# avec joblib\n",
        "\n",
        "filename = 'Models/best1_model.sav'\n",
        "joblib.dump(xgb, filename)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KzQ-ULQbh3E5"
      },
      "source": [
        "### Deep Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbSkwnLTh6MU",
        "outputId": "20e6c4e8-d4c6-4f75-c57c-f8072d2fe2e8"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape, output_shape):\n",
        "\n",
        "  input  = tf.keras.Input( shape = input_shape )\n",
        "  output = tf.keras.layers.Dense( 128 , activation = \"relu\" )( input )\n",
        "  output = tf.keras.layers.Dense( 256 , activation = \"relu\" )( input )\n",
        "  lstm   = tf.keras.layers.LSTM(256)( output ) \n",
        "  output = tf.keras.layers.Dense( 256 , activation = \"relu\" )( lstm )\n",
        "  output = tf.keras.layers.Dense( 256 , activation = \"relu\" )( output )\n",
        "  output = tf.keras.layers.Dense(  5  , activation = \"softmax\" )( output )\n",
        "\n",
        "  model = tf.keras.Model( inputs= input , outputs= output )\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model( \n",
        "    input_shape = (3, 4), # 3 lectures pour 4 features chacune\n",
        "    output_shape = 2\n",
        " )\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmGXeBJkkmos"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    metrics = [utils.get_f1, 'accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tm_wmMfiQPu",
        "outputId": "5b30f625-8aba-4b0e-e226-9f759a2019f9"
      },
      "outputs": [],
      "source": [
        "# donnees\n",
        "\n",
        "rw_dred_cleaned = rw_dred.drop(['Pn'] , axis=1)\n",
        "rw_qud_cleaned  = rw_qud.drop(['Pn'] , axis=1)\n",
        "\n",
        "## dred\n",
        "dred_train = rw_dred_cleaned[:int(df_dred.shape[0]*0.8)]\n",
        "dred_test = rw_dred_cleaned[int(df_dred.shape[0]*0.8):]\n",
        "print(dred_train.head())\n",
        "\n",
        "## qud\n",
        "qud_train = rw_qud_cleaned[:int(df_qud.shape[0]*0.8)]\n",
        "qud_test = rw_qud_cleaned[int(df_qud.shape[0]*0.8):]\n",
        "print(qud_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm7kLaaUk37Q",
        "outputId": "85d7672e-90e5-4685-c045-e3e8ebfb3c94"
      },
      "outputs": [],
      "source": [
        "#dred\n",
        "\n",
        "generateur_train = utils.Generateur(dred_train, window_size=3, batch_size=256)\n",
        "generateur_test = utils.Generateur(dred_test, window_size=3, batch_size=256)\n",
        "\n",
        "# print((generateur_train[0]))\n",
        "dred_hist = model.fit(\n",
        "    x = generateur_train,\n",
        "    epochs=10,\n",
        "    validation_data = generateur_test\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akx0pd3nwmIh",
        "outputId": "80ce53bf-e9cd-4a5c-e5d9-88bc5b2b1f7d"
      },
      "outputs": [],
      "source": [
        "#qud\n",
        "\n",
        "generateur_train = utils.Generateur(qud_train, window_size=3, batch_size=256)\n",
        "generateur_test = utils.Generateur(qud_test, window_size=3, batch_size=256)\n",
        "\n",
        "# print((generateur_train[0]))\n",
        "qud_hist = model.fit(\n",
        "    x = generateur_train,\n",
        "    epochs=10,\n",
        "    validation_data = generateur_test\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "awxDKgBT3U3z"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
